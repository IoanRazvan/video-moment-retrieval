{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from video_moment_retrieval.utils.logging import init_logging, logger\n",
    "from video_moment_retrieval.datasets.qv_highlights import QVDataset, pad_collate\n",
    "from video_moment_retrieval.moment_detr.model import VideoDetrConfig, MomentDetr\n",
    "from transformers import TrainingArguments, Trainer, EvalPrediction\n",
    "\n",
    "init_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "import numpy.typing as npt\n",
    "from scipy.special import softmax\n",
    "from video_moment_retrieval.detr_matcher.matcher import center_to_edges\n",
    "from video_moment_retrieval.eval.eval import compute_mr_ap\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def process_preds_and_labels(eval_preds: EvalPrediction) -> tuple[list[dict[str, Any]], list[list[float]]]:\n",
    "    # eval.label_ids -> list[list[dict[str, np.array]]]\n",
    "    # eval.predictions -> list[tuple[np.array, np.array]]\n",
    "    labels = []\n",
    "    predictions = []\n",
    "    for batch_idx in range(len(eval_preds.label_ids)):\n",
    "        batch_labels = eval_preds.label_ids[batch_idx]\n",
    "        batch_predictions = eval_preds.predictions[batch_idx]\n",
    "        # moments and scores are each batch_size x 10 x 2\n",
    "        moments, scores = batch_predictions\n",
    "        scores = softmax(scores, -1)[..., 0]  # batch_size x 10\n",
    "        \n",
    "        for video_labels, video_predictions, video_scores in zip(batch_labels, moments, scores):\n",
    "            qid_label, qid_prediction = [], []\n",
    "            gt_windows = center_to_edges(video_labels[\"boxes\"]) * video_labels[\"duration\"]\n",
    "            pred_windows = center_to_edges(video_predictions) * video_labels[\"duration\"]\n",
    "            \n",
    "            qid_prediction = [(window[0].item(), window[1].item(), score) for window, score in zip(pred_windows, video_scores)]\n",
    "            qid_label = [(window[0].item(), window[1].item()) for window in gt_windows]\n",
    "            \n",
    "        \n",
    "            labels.append(qid_label)\n",
    "            predictions.append(qid_prediction)\n",
    "    \n",
    "    return labels, predictions  \n",
    "\n",
    "def compute_metrics(eval_preds: EvalPrediction):\n",
    "    labels, predictions = process_preds_and_labels(eval_preds)\n",
    "    metrics_dict = compute_mr_ap(predictions, labels, num_workers=8)\n",
    "    \n",
    "    return {\n",
    "        \"mAP@0.5\": metrics_dict[\"0.5\"],\n",
    "        \"mAP@0.7\": metrics_dict[\"0.7\"],\n",
    "        \"mAP\": metrics_dict[\"average\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-19 07:42:02,421 - INFO video_moment_retrieval - 2358234223.py:22 - Running model using config VideoDetrConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"auxiliary_loss\": false,\n",
      "  \"backbone\": \"resnet50\",\n",
      "  \"backbone_config\": null,\n",
      "  \"backbone_kwargs\": {\n",
      "    \"in_chans\": 3,\n",
      "    \"out_indices\": [\n",
      "      1,\n",
      "      2,\n",
      "      3,\n",
      "      4\n",
      "    ]\n",
      "  },\n",
      "  \"bbox_cost\": 10,\n",
      "  \"bbox_loss_coefficient\": 10,\n",
      "  \"ce_loss_coefficient\": 4,\n",
      "  \"class_cost\": 4,\n",
      "  \"d_model\": 256,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 1024,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 2,\n",
      "  \"dice_loss_coefficient\": 1,\n",
      "  \"dilation\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 1024,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 2,\n",
      "  \"eos_coefficient\": 0.1,\n",
      "  \"giou_cost\": 1,\n",
      "  \"giou_loss_coefficient\": 1,\n",
      "  \"hinge_loss_margin\": 0.2,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"init_xavier_std\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"mask_loss_coefficient\": 1,\n",
      "  \"model_type\": \"detr\",\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 2,\n",
      "  \"num_queries\": 10,\n",
      "  \"position_embedding_type\": \"sine\",\n",
      "  \"saliency_loss_coefficient\": 2,\n",
      "  \"text_embedding_dim\": 512,\n",
      "  \"transformers_version\": \"4.41.2\",\n",
      "  \"use_pretrained_backbone\": true,\n",
      "  \"use_timm_backbone\": true,\n",
      "  \"video_embedding_dim\": 512\n",
      "}\n",
      "\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22600' max='22600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22600/22600 1:51:33, Epoch 200/200]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Map@0.5</th>\n",
       "      <th>Map@0.7</th>\n",
       "      <th>Map</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>5.305400</td>\n",
       "      <td>6.399514</td>\n",
       "      <td>13.070000</td>\n",
       "      <td>5.510000</td>\n",
       "      <td>5.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>4.299000</td>\n",
       "      <td>4.339568</td>\n",
       "      <td>21.630000</td>\n",
       "      <td>9.260000</td>\n",
       "      <td>9.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>4.096500</td>\n",
       "      <td>4.341559</td>\n",
       "      <td>22.020000</td>\n",
       "      <td>9.800000</td>\n",
       "      <td>10.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>3.997800</td>\n",
       "      <td>4.376107</td>\n",
       "      <td>25.360000</td>\n",
       "      <td>11.950000</td>\n",
       "      <td>11.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>3.896700</td>\n",
       "      <td>4.363026</td>\n",
       "      <td>22.540000</td>\n",
       "      <td>9.090000</td>\n",
       "      <td>9.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>3.817500</td>\n",
       "      <td>4.394557</td>\n",
       "      <td>25.250000</td>\n",
       "      <td>11.040000</td>\n",
       "      <td>11.590000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>3.739000</td>\n",
       "      <td>4.393754</td>\n",
       "      <td>28.060000</td>\n",
       "      <td>12.010000</td>\n",
       "      <td>12.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>3.571400</td>\n",
       "      <td>4.651382</td>\n",
       "      <td>30.790000</td>\n",
       "      <td>14.690000</td>\n",
       "      <td>14.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>3.415400</td>\n",
       "      <td>4.394294</td>\n",
       "      <td>35.410000</td>\n",
       "      <td>18.430000</td>\n",
       "      <td>17.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>3.282500</td>\n",
       "      <td>4.613762</td>\n",
       "      <td>37.320000</td>\n",
       "      <td>18.620000</td>\n",
       "      <td>18.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>3.159100</td>\n",
       "      <td>4.360634</td>\n",
       "      <td>39.890000</td>\n",
       "      <td>20.620000</td>\n",
       "      <td>19.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>3.043000</td>\n",
       "      <td>4.478027</td>\n",
       "      <td>39.900000</td>\n",
       "      <td>19.710000</td>\n",
       "      <td>19.280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>2.916100</td>\n",
       "      <td>4.693605</td>\n",
       "      <td>41.020000</td>\n",
       "      <td>20.780000</td>\n",
       "      <td>19.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>2.800600</td>\n",
       "      <td>4.625392</td>\n",
       "      <td>43.230000</td>\n",
       "      <td>22.630000</td>\n",
       "      <td>20.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>2.686600</td>\n",
       "      <td>4.993107</td>\n",
       "      <td>43.860000</td>\n",
       "      <td>22.710000</td>\n",
       "      <td>21.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>2.596200</td>\n",
       "      <td>4.987356</td>\n",
       "      <td>44.460000</td>\n",
       "      <td>23.840000</td>\n",
       "      <td>21.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>2.499200</td>\n",
       "      <td>5.125275</td>\n",
       "      <td>45.390000</td>\n",
       "      <td>23.580000</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>2.382300</td>\n",
       "      <td>5.135865</td>\n",
       "      <td>45.740000</td>\n",
       "      <td>25.700000</td>\n",
       "      <td>23.570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>2.311200</td>\n",
       "      <td>5.590934</td>\n",
       "      <td>46.270000</td>\n",
       "      <td>24.560000</td>\n",
       "      <td>22.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>2.233900</td>\n",
       "      <td>5.260125</td>\n",
       "      <td>47.120000</td>\n",
       "      <td>26.740000</td>\n",
       "      <td>24.370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>2.138500</td>\n",
       "      <td>5.427317</td>\n",
       "      <td>45.420000</td>\n",
       "      <td>24.960000</td>\n",
       "      <td>22.590000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>2.056900</td>\n",
       "      <td>5.576249</td>\n",
       "      <td>45.100000</td>\n",
       "      <td>24.370000</td>\n",
       "      <td>22.390000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=22600, training_loss=3.2124608909134316, metrics={'train_runtime': 6699.025, 'train_samples_per_second': 215.494, 'train_steps_per_second': 3.374, 'total_flos': 0.0, 'train_loss': 3.2124608909134316, 'epoch': 200.0})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_dataset = QVDataset(\"qvhighlights_features\\\\text_features\", \"qvhighlights_features\\\\video_features\", \"qvhighlights_features\\\\highlight_train_release.jsonl\")\n",
    "eval_dataset = QVDataset(\"qvhighlights_features\\\\text_features\", \"qvhighlights_features\\\\video_features\", \"qvhighlights_features\\\\highlight_val_release.jsonl\")\n",
    "\n",
    "config = VideoDetrConfig(\n",
    "    d_model=256,\n",
    "    encoder_layers=2,\n",
    "    encoder_ffn_dim=1024,\n",
    "    decoder_layers=2,\n",
    "    decoder_ffn_dim=1024,\n",
    "    num_queries=10,\n",
    "    dropout=0.1,\n",
    "    activation_dropout=0.1,\n",
    "    giou_cost=1,\n",
    "    bbox_cost=10,\n",
    "    class_cost=4,\n",
    "    giou_loss_coefficient=1,\n",
    "    bbox_loss_coefficient=10,\n",
    "    ce_loss_coefficient=4,\n",
    "    num_labels=1,\n",
    "    saliency_loss_coefficient=2\n",
    ")\n",
    "logger.info(\"Running model using config %s\", config)\n",
    "\n",
    "model = MomentDetr(config)\n",
    "\n",
    "train_args = TrainingArguments(\n",
    "    \"./train_output\",\n",
    "    per_device_train_batch_size=32,\n",
    "    gradient_accumulation_steps=2,\n",
    "    learning_rate=1e-4,\n",
    "    lr_scheduler_type=\"constant_with_warmup\",\n",
    "    warmup_steps=500,\n",
    "    num_train_epochs=200,\n",
    "    save_steps=1000,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=1000,\n",
    "    load_best_model_at_end=True,\n",
    "    greater_is_better=True,\n",
    "    max_grad_norm=0.1,\n",
    "    label_names=[\"labels\"],\n",
    "    weight_decay=1e-4,\n",
    "    eval_do_concat_batches=False,\n",
    "    metric_for_best_model=\"mAP\"\n",
    "    # use_cpu=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=train_args,\n",
    "    data_collator=pad_collate,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3800, 0.2000]])\n",
      "tensor([[0.5170, 0.1521],\n",
      "        [0.2624, 0.1437],\n",
      "        [0.8812, 0.1701],\n",
      "        [0.6829, 0.2108]], grad_fn=<IndexBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from video_moment_retrieval.datasets.qv_highlights import QVDataset, pad_collate\n",
    "\n",
    "val_dataset = QVDataset(\"qvhighlights_features\\\\text_features\", \"qvhighlights_features\\\\video_features\", \"qvhighlights_features\\\\highlight_val_release.jsonl\")\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, collate_fn=pad_collate, shuffle=True)\n",
    "batch = next(iter(val_loader))\n",
    "model = model.to(\"cpu\")\n",
    "output = model(**batch)\n",
    "print(batch[\"labels\"][0][\"boxes\"])\n",
    "scores = output.logits.softmax(axis=-1)[0, :, 0]\n",
    "moments = output.predicted_moments[0, scores > 0.5, :]\n",
    "print(moments)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
